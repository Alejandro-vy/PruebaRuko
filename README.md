# ğŸ“Š Prueba TÃ©cnica â€“ Ruklo

Este proyecto resuelve dos desafÃ­os planteados por Ruklo mediante el procesamiento de un archivo JSON con eventos simulados de clientes. Se implementÃ³ usando **Spring Boot**, con Ã©nfasis en la correcta modelaciÃ³n del problema, claridad de la lÃ³gica y escalabilidad.

---

## âœ… Requisitos TÃ©cnicos

- **Java 17** o superior
- **Maven 3.8+**
- Sistema operativo compatible (Windows, Linux, macOS)
- Archivo de eventos: `ruklo_events_1000.json` ubicado en `src/main/resources/`

---

## ğŸš€ CÃ³mo ejecutar el programa

1. Clona este repositorio:
   ```bash
   https://github.com/Alejandro-vy/PruebaRuko.git
   cd PruebaRuko
   
2. Compila el proyecto:
   ```bash
   mvn clean install
3. Ejecuta la aplicaciÃ³n: 
   ```bash
   mvn spring-boot:run
4. Archivos generados:

- Al finalizar la ejecuciÃ³n, se generarÃ¡n dos archivos en la carpeta outputs/:

  - benefits_output.json

  - summary_output.json   
   
# DescripciÃ³n del problema y soluciones

## Parte 1 â€“ Requerimientos
1. Detectar clientes con 5 visitas seguidas sin recarga.

Punto 1:
  
   - Se procesan los eventos por cliente y tienda.

   - Se identifican secuencias de 5 visitas consecutivas sin recargas entre medio.

   - Se otorga un beneficio por cada secuencia encontrada.
  
Punto 2:

   - Para esta primera instancia, se eligiÃ³ guardar los beneficios en un archivo JSON, dado el contexto de prueba tÃ©cnica. Sin embargo, como se muestra en el diagrama ubicado en PruebaRuko/outputs/PruebaRuko DiagramaUML.PNG, una mejor soluciÃ³n a futuro es implementar una base de datos relacional, lo que permitirÃ­a una trazabilidad mÃ¡s robusta y un formato de datos estandarizado. Ejemplo Diagrama UML: ![Modelo Diagrama de clases UML](/outputs/PruebaRuko DiagramaUML.PNG)

Punto 3:

   - Para evitar errores y mantener buen rendimiento con grandes volÃºmenes de datos, usarÃ­a: Una base de datos como mecionÃ© anteriormente para almacenar los beneficios y los eventos, tambiÃ©n es importante guardar las validaciones y logs para el control de errores, validaciÃ³n de datos y trazabilidad mediante logging, lo cual considero muy importante al trabajar con grandes volumenes de datos. Finalmente ImplementarÃ­a un script ETL que gestione la carga de los archivos JSON, garantizando su integridad antes de llegar a la base de datos y al backend.


ğŸ—‚ Resultado: benefits_output.json

ğŸ“¦ Modelo: ClientVisitStreak ubicado en `src/main/java/com.example.PruebaRuko/model/ClientVisitStreak.java`




2. Historial de transacciones por cliente, agrupado por tipo y semana


   - Se genera un resumen por cliente, agrupado semanalmente.

   - Se incluyen todas las semanas, incluso aquellas sin recargas.

   - Se calcula el promedio de monto recargado por semana (0 si no hubo recargas).

   - Las semanas se ordenan cronolÃ³gicamente para facilitar el anÃ¡lisis.


ğŸ—‚ Resultado: summary_output.json

ğŸ“¦ Modelo: ClientTransactionSummary ubicado en `src/main/java/com.example.PruebaRuko/model/ClientTransactionSummary.java`


## ğŸ“ Estructura del proyecto

```bash
   src/
   â”œâ”€â”€ main/
   â”‚   â”œâ”€â”€ java/
   â”‚   â”‚   â””â”€â”€ com.example.PruebaRuko/
   â”‚   â”‚       â”œâ”€â”€ model/
   â”‚   â”‚       â”œâ”€â”€ service/
   â”‚   â”‚       â””â”€â”€ runner/
   â”‚   â””â”€â”€ resources/
   â”‚       â””â”€â”€ ruklo_events_1000.json
   â””â”€â”€ outputs/
       â”œâ”€â”€ benefits_output.json
       â””â”€â”€ summary_output.json
       â””â”€â”€ PruebaRuko DiagramaUML.png
       
```
                     




## Parte 2 - Preguntas

### Limitaciones actuales:

- Procesamiento en memoria, toda la data se carga y procesa en memoria, lo que puede causar problemas de rendimiento o errores por falta de recursos.

- No se utiliza base de datos, lo que impide consultas dinamicas y/o almacenamiento historico de los datos

- Resultados estÃ¡ticos en archivos JSON

- No hay control de concurrencia, ni validaciÃ³n de duplicados

- Cada ejecuciÃ³n reprocesa todo el archivo, incluso eventos ya procesados. Por lo cual no es incremental.

### Escenario con 100.000 eventos diarios:

   - El rendimiento disminuirÃ­a considerablemente, tiempos de ejecuciÃ³n altos.

   - Posible error de memoria por el aumento de datos.

   - Dificil de mantener

Para escalar, se recomienda:

   - Persistencia en base de datos con Ã­ndices.

   - Procesamiento incremental o por lotes.

   - Uso de arquitectura orientada a eventos o de microservicios.

   - ExposiciÃ³n de resultados mediante de una APIs REST.

# Autor
Desarrollado por: [Alejandro Vera]

